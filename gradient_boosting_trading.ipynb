{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gradient_boosting_trading",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shau0000/trading-startegy-for-indian-equities-using-gradient-boosting/blob/main/gradient_boosting_trading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DE_HnoZaNOjJ",
        "outputId": "84ae3d1c-4ef5-4cb9-d36d-02b463ede764"
      },
      "source": [
        "!pip install alphalens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting alphalens\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/93/3afd2bb2b4a7629b5c99209f1e272290b7125373e46ceb11fba14e675562/alphalens-0.4.0.tar.gz (24.0MB)\n",
            "\u001b[K     |████████████████████████████████| 24.0MB 123kB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from alphalens) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from alphalens) (1.19.5)\n",
            "Requirement already satisfied: pandas>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from alphalens) (1.1.5)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from alphalens) (1.4.1)\n",
            "Requirement already satisfied: seaborn>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from alphalens) (0.11.1)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from alphalens) (0.10.2)\n",
            "Requirement already satisfied: IPython>=3.2.3 in /usr/local/lib/python3.7/dist-packages (from alphalens) (5.5.0)\n",
            "Collecting empyrical>=0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/43/1b997c21411c6ab7c96dc034e160198272c7a785aeea7654c9bcf98bec83/empyrical-0.5.5.tar.gz (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->alphalens) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->alphalens) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->alphalens) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->alphalens) (1.3.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.0->alphalens) (2018.9)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.6.1->alphalens) (0.5.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from IPython>=3.2.3->alphalens) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython>=3.2.3->alphalens) (0.8.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython>=3.2.3->alphalens) (5.0.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython>=3.2.3->alphalens) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython>=3.2.3->alphalens) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython>=3.2.3->alphalens) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython>=3.2.3->alphalens) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython>=3.2.3->alphalens) (57.0.0)\n",
            "Requirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.7/dist-packages (from empyrical>=0.5.0->alphalens) (0.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=1.4.0->alphalens) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->IPython>=3.2.3->alphalens) (0.7.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->IPython>=3.2.3->alphalens) (0.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython>=3.2.3->alphalens) (0.2.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->alphalens) (2.23.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->alphalens) (4.2.6)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->alphalens) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->alphalens) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->alphalens) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->alphalens) (2021.5.30)\n",
            "Building wheels for collected packages: alphalens, empyrical\n",
            "  Building wheel for alphalens (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alphalens: filename=alphalens-0.4.0-cp37-none-any.whl size=24027576 sha256=ae232c0f49d78eebaed8024afb604f6cc6fbf1e890dd95e9e190251ef56bb194\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/fb/58/653997175d0e91a6459d84eb52e0989cf5348f0a569bd06ef5\n",
            "  Building wheel for empyrical (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for empyrical: filename=empyrical-0.5.5-cp37-none-any.whl size=39780 sha256=5df1e87ad3eb240b11034c01297b2ce57025792ef010361c93b24f734c5b89c6\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/b2/c8/6769d8444d2f2e608fae2641833110668d0ffd1abeb2e9f3fc\n",
            "Successfully built alphalens empyrical\n",
            "Installing collected packages: empyrical, alphalens\n",
            "Successfully installed alphalens-0.4.0 empyrical-0.5.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89mtiymKFU3-",
        "outputId": "4838aeb0-86df-4aec-95cd-e5f0d680ac60"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJ1wsMcANF7_",
        "outputId": "e43eee17-a713-4747-f9d4-a84fcf4fd7d5"
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/41/24e14322b9986cf72a8763e0a0a69cc256cf963cf9502c8f0044a62c1ae8/catboost-0.26-cp37-none-manylinux1_x86_64.whl (69.2MB)\n",
            "\u001b[K     |████████████████████████████████| 69.2MB 43kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.19.5)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.1.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJduA2C3MZWy"
      },
      "source": [
        "from pathlib import Path\n",
        "import sys, os\n",
        "from time import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "from collections import defaultdict\n",
        "from itertools import product\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import lightgbm as lgb\n",
        "from catboost import Pool, CatBoostRegressor\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "from alphalens.tears import (create_summary_tear_sheet,\n",
        "                             create_full_tear_sheet)\n",
        "\n",
        "from alphalens.utils import get_clean_factor_and_forward_returns\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from utils1 import MultipleTimeSeriesCV\n",
        "lr = LinearRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDjF78slNDOp"
      },
      "source": [
        "year = 252\n",
        "idx = pd.IndexSlice"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jm-oR4UtNeA7"
      },
      "source": [
        "prices=pd.read_csv(\"/content/drive/MyDrive/QUANTL files/gradient_boosting/prices.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11x6rF72Ntay"
      },
      "source": [
        "prices=prices.loc[prices['date']<'2020-01-01'].set_index(['date','ticker'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RztqnIwsPYii"
      },
      "source": [
        "features=[]\n",
        "labels=[]\n",
        "for i in prices.columns:\n",
        "  if ('frd') in i:\n",
        "    labels.append(i)\n",
        "  else:\n",
        "    features.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpzLmSRuP5zu"
      },
      "source": [
        "categorical_col=['year','month','weekday','Industry']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kma86Cf4Q0yd"
      },
      "source": [
        "train_length=[int(7*year),year]\n",
        "test_length=[63,21]\n",
        "lookahead=[1,5,21]\n",
        "test_params=list(product(train_length,test_length,lookahead))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFJHok7mRmUF",
        "outputId": "03e4dc6b-054d-43c8-a808-2f409db3f619"
      },
      "source": [
        "lr_metrics=[]\n",
        "for train_length,test_length,lookahead in tqdm(test_params):\n",
        "  print(train_length,test_length,lookahead)\n",
        "  label=f'r{lookahead:02}frd' \n",
        "  df=pd.get_dummies(prices.loc[:,features+[label]].dropna(),columns=categorical_col,drop_first=True)\n",
        "  X,Y=df.drop(label,axis=1),df[label]\n",
        "  n_splits=int(2*year/test_length)\n",
        "  cv=MultipleTimeSeriesCV(n_splits=n_splits,test_period_length=test_length,lookahead=lookahead,train_period_length=train_length)\n",
        "  ic,preds=[],[]\n",
        "  for i,(train_idx,test_idx) in enumerate(cv.split(X=X)):\n",
        "    X_train,Y_train=X.iloc[train_idx],Y.iloc[train_idx]\n",
        "    X_test,Y_test=X.iloc[test_idx],Y.iloc[test_idx]\n",
        "    lr.fit(X_train,Y_train)\n",
        "    pred=lr.predict(X_test)\n",
        "    preds.append(Y_test.to_frame('Y_true').assign(y_pred=pred))\n",
        "    ic.append(spearmanr(Y_test,pred)[0])\n",
        "  preds_df=pd.concat(preds)\n",
        "  lr_metrics.append([lookahead,train_length,test_length,np.mean(ic),spearmanr(preds_df.Y_true,preds_df.y_pred)[0]])\n",
        "\n",
        "columns=['lookahead','train_length','test_length','ic_by_day','ic']\n",
        "lr_metrics=pd.DataFrame(lr_metrics,columns=columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1764 63 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "  8%|▊         | 1/12 [00:37<06:53, 37.55s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1764 63 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 17%|█▋        | 2/12 [01:14<06:14, 37.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1764 63 21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 25%|██▌       | 3/12 [01:52<05:36, 37.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1764 21 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 33%|███▎      | 4/12 [03:45<08:00, 60.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1764 21 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 42%|████▏     | 5/12 [05:36<08:47, 75.42s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1764 21 21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 50%|█████     | 6/12 [07:28<08:38, 86.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "252 63 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 58%|█████▊    | 7/12 [07:36<05:14, 62.89s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "252 63 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 67%|██████▋   | 8/12 [07:44<03:05, 46.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "252 63 21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 75%|███████▌  | 9/12 [07:52<01:45, 35.02s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "252 21 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 83%|████████▎ | 10/12 [08:13<01:01, 30.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "252 21 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 11/12 [08:34<00:27, 27.84s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "252 21 21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 12/12 [08:56<00:00, 44.69s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "Ir9gJzGJS_EE",
        "outputId": "bab44519-d1c6-4dbf-b46f-60c53c48e58f"
      },
      "source": [
        "lr_metrics.groupby('lookahead',group_keys=False).apply(lambda x:x.nlargest(3,'ic_by_day'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lookahead</th>\n",
              "      <th>train_length</th>\n",
              "      <th>test_length</th>\n",
              "      <th>ic_by_day</th>\n",
              "      <th>ic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1764</td>\n",
              "      <td>63</td>\n",
              "      <td>0.066489</td>\n",
              "      <td>0.057986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>252</td>\n",
              "      <td>21</td>\n",
              "      <td>0.050989</td>\n",
              "      <td>-0.000465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1764</td>\n",
              "      <td>21</td>\n",
              "      <td>0.048601</td>\n",
              "      <td>0.025675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>5</td>\n",
              "      <td>252</td>\n",
              "      <td>21</td>\n",
              "      <td>0.105787</td>\n",
              "      <td>0.029835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>1764</td>\n",
              "      <td>63</td>\n",
              "      <td>0.105157</td>\n",
              "      <td>0.081594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1764</td>\n",
              "      <td>21</td>\n",
              "      <td>0.079991</td>\n",
              "      <td>-0.003850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21</td>\n",
              "      <td>1764</td>\n",
              "      <td>63</td>\n",
              "      <td>0.180257</td>\n",
              "      <td>0.155919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>21</td>\n",
              "      <td>252</td>\n",
              "      <td>63</td>\n",
              "      <td>0.129876</td>\n",
              "      <td>0.003746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>21</td>\n",
              "      <td>1764</td>\n",
              "      <td>21</td>\n",
              "      <td>0.124327</td>\n",
              "      <td>0.111366</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    lookahead  train_length  test_length  ic_by_day        ic\n",
              "0           1          1764           63   0.066489  0.057986\n",
              "9           1           252           21   0.050989 -0.000465\n",
              "3           1          1764           21   0.048601  0.025675\n",
              "10          5           252           21   0.105787  0.029835\n",
              "1           5          1764           63   0.105157  0.081594\n",
              "4           5          1764           21   0.079991 -0.003850\n",
              "2          21          1764           63   0.180257  0.155919\n",
              "8          21           252           63   0.129876  0.003746\n",
              "5          21          1764           21   0.124327  0.111366"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9awp-maBfo5i"
      },
      "source": [
        "lr_metrics.to_csv(\"/content/drive/MyDrive/QUANTL files/gradient_boosting/linear_regression_score.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOC4SEHBf6jp"
      },
      "source": [
        "\n",
        "LightGBM Model Tuning¶\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGRm6Aisdin4"
      },
      "source": [
        "def get_fi(model):\n",
        "  fi=model.feature_importance(importance_type='gain')\n",
        "  return (pd.Series(fi/fi.sum(),index=model.feature_name()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jayYOb6Mew-4"
      },
      "source": [
        "base_params = dict(boosting='gbdt',\n",
        "                   objective='regression',\n",
        "                   verbose=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zxFqvKMex8Z"
      },
      "source": [
        "max_depths = [2, 3, 5, 7]\n",
        "num_leaves_opts = [2 ** i for i in max_depths]\n",
        "min_data_in_leaf_opts = [250, 500, 1000]\n",
        "\n",
        "# weight of each new tree in the ensemble\n",
        "learning_rate_ops = [.01, .1, .3]\n",
        "\n",
        "# random feature selection\n",
        "feature_fraction_opts = [.3, .6, .95]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PM3upFJoe7rs"
      },
      "source": [
        "param_names = ['learning_rate', 'num_leaves','feature_fraction', 'min_data_in_leaf']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKBQgkkufIKc"
      },
      "source": [
        "cv_params=list(product(learning_rate_ops ,num_leaves_opts,feature_fraction_opts,min_data_in_leaf_opts))\n",
        "n_params=len(cv_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hN4Uf4zAgULI"
      },
      "source": [
        "lookaheads = [5, 21]\n",
        "train_lengths = [int(7 * 252)]\n",
        "test_lengths = [63]\n",
        "test_params = list(product(lookaheads, train_lengths, test_lengths))\n",
        "n = len(test_params)\n",
        "test_param_sample = np.random.choice(list(range(n)), size=int(n), replace=False)\n",
        "test_params = [test_params[i] for i in test_param_sample]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vP9TemegZ-g"
      },
      "source": [
        "categoricals = ['year', 'weekday', 'month']\n",
        "for feature in categoricals:\n",
        "    prices[feature] = pd.factorize(prices[feature], sort=True)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aB9c-k8iiVCh"
      },
      "source": [
        "def ic_lgbm(preds, train_data):\n",
        "    \"\"\"Custom IC eval metric for lightgbm\"\"\"\n",
        "    is_higher_better = True\n",
        "    return 'ic', spearmanr(preds, train_data.get_label())[0], is_higher_better"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ERlodFbM1F5"
      },
      "source": [
        "label_dict=dict(zip(lookaheads,labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FU_6HPVcd_8_"
      },
      "source": [
        "num_iterations = [10, 25, 50, 75] + list(range(100, 501, 50))\n",
        "num_boost_round = num_iterations[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilv0KBK9mShb"
      },
      "source": [
        "metric_cols = (param_names + ['daily_ic_mean', 'daily_ic_mean_n',\n",
        "                              'daily_ic_median', 'daily_ic_median_n'] +\n",
        "               [str(n) for n in num_iterations])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnkRx9AkRMJf"
      },
      "source": [
        "for lookahead,train_length,test_length in tqdm(test_params):\n",
        "  cvp=np.random.choice(list(range(n_params)),size=int(n_params/4),replace=False)\n",
        "  cv_params_=[cv_params[i] for i in cvp]\n",
        "  n_splits=int((2*year)/test_length)\n",
        "  cv=MultipleTimeSeriesCV(n_splits=n_splits,lookahead=lookahead,train_period_length=train_length,test_period_length=test_length)\n",
        "  label=label_dict[lookahead]\n",
        "  outcome_data=prices.loc[:,features+[label]].dropna()\n",
        "  lgb_data=lgb.Dataset(data=outcome_data.drop(label,axis=1),label=outcome_data[label],categorical_feature=categoricals,free_raw_data=False)\n",
        "  predictions,metrics,feature_importance,daily_ic=[],[],[],[]\n",
        "  for p,param_values in enumerate(cv_params_):\n",
        "    key=f'{lookahead}-{train_length}-{test_length}-'+'-'.join([str(p) for p in param_values])\n",
        "    params=dict(zip(param_names,param_values))\n",
        "    params.update(base_params)\n",
        "    cv_preds,n_rounds=[],[]\n",
        "    ic_cv=defaultdict(list)\n",
        "    for i,(train_idx,test_idx) in enumerate(cv.split(X=outcome_data)):\n",
        "      lgb_train = lgb_data.subset(used_indices=train_idx.tolist(),params=params).construct()\n",
        "      model=lgb.train(params=params,train_set=lgb_train,num_boost_round=num_boost_round,verbose_eval=False)\n",
        "      if i==0:\n",
        "        fi=get_fi(model).to_frame()\n",
        "      else:\n",
        "        fi[i]=get_fi(model)\n",
        "      test_set=outcome_data.iloc[test_idx,:]\n",
        "      X_test=test_set.loc[:,model.feature_name()]\n",
        "      y_test=test_set.loc[:,label]\n",
        "      y_pred={str(n): model.predict(X_test, num_iteration=n) for n in num_iterations}\n",
        "      cv_preds.append(y_test.to_frame('y_test').assign(**y_pred).assign(i=i))\n",
        "    cv_preds=pd.concat(cv_preds)\n",
        "    by_day=cv_preds.groupby(level='date')\n",
        "    ic_by_day = pd.concat([by_day.apply(lambda x: spearmanr(x.y_test, x[str(n)])[0]).to_frame(n) for n in num_iterations], axis=1)\n",
        "    daily_ic_mean = ic_by_day.mean()\n",
        "    daily_ic_mean_n = daily_ic_mean.idxmax()\n",
        "    daily_ic_median = ic_by_day.median()\n",
        "    daily_ic_median_n = daily_ic_median.idxmax()\n",
        "    ic=[spearmanr(cv_preds.y_test,cv_preds[str(n)])[0] for n in num_iterations]\n",
        "    metrics = pd.Series(list(param_values)+[daily_ic_mean.max(), daily_ic_mean_n, daily_ic_median.max(),daily_ic_median_n]+ic,index=metric_cols)    \n",
        "    metrics.to_csv(\"/content/drive/MyDrive/QUANTL files/gradient_boosting/metrics\"+key+\".csv\")\n",
        "    ic_by_day.assign(**params).to_csv('/content/drive/MyDrive/QUANTL files/gradient_boosting/ic_by_day'+key+'.csv')\n",
        "    fi.T.describe().T.assign(**params).to_csv('/content/drive/MyDrive/QUANTL files/gradient_boosting/fi'+key+'.csv')\n",
        "    cv_preds.to_csv('/content/drive/MyDrive/QUANTL files/gradient_boosting/gradient_boosting_prediction'+key+'.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBZ8C6LBdtWE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}